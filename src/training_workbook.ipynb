{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897126b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from terrain_classification.svm_classification.train_svm import SVMClassification\n",
    "# from terrain_classification.svm_classification.predict_svm import PredictSVM\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5047f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"terrain_classification\"))\n",
    "\n",
    "def create_label_dict(files:dict=None, parent_directory:str=None):\n",
    "    if parent_directory == None:\n",
    "        parent_directory = os.path.abspath(os.path.join(os.getcwd(), \"terrain_classification\"))\n",
    "\n",
    "    label_files = {}\n",
    "    for key_ in files.keys():\n",
    "        for file_ in files[key_]:\n",
    "            label_files[os.path.join(parent_directory, 'data/force_torque', key_, file_)] = key_\n",
    "\n",
    "    return label_files\n",
    "\n",
    "train_files = ['1', '2', '3', '4', '5', '6', ]\n",
    "validate_files = ['7', '8']\n",
    "# train_files = ['1', '2', '3', '4',]\n",
    "# validate_files = [ '5', '6', '7', '8']\n",
    "\n",
    "training_file_list = [f\"trial{file_no}.csv\" for file_no in train_files]\n",
    "validation_file_list = [f\"trial{file_no}.csv\" for file_no in validate_files]\n",
    "\n",
    "files_to_train = {\n",
    "    \"sand\": training_file_list,\n",
    "    \"wood\": training_file_list,\n",
    "    # \"concrete\": train_files,\n",
    "    \"gravel\": training_file_list,\n",
    "    \"clay\": training_file_list,\n",
    "}\n",
    "files_to_validate = {\n",
    "    \"sand\": validation_file_list,\n",
    "    \"wood\": validation_file_list,\n",
    "    # \"concrete\": validation_file_list,\n",
    "    \"gravel\": validation_file_list,\n",
    "    \"clay\": validation_file_list,\n",
    "}\n",
    "\n",
    "train_data_labels = create_label_dict(files_to_train, parent_dir)\n",
    "validation_data_labels = create_label_dict(files_to_validate, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d61b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_same_length(features_, labels_):\n",
    "    \"\"\"\n",
    "    Adjusts the length of the data arrays to be the same by padding with zeros.\n",
    "    \"\"\"\n",
    "    if len(labels_) == 0:\n",
    "        print(\"Cannot adjust since the length is zero\")\n",
    "        return None, None, False\n",
    "    unique_labels, label_counts = np.unique(labels_, return_counts=True)\n",
    "\n",
    "    min_count = min(label_counts)\n",
    "    #extract index of all unique labels\n",
    "    indices = []\n",
    "    for label in unique_labels:\n",
    "        id_ = np.where(labels_ == label)[0]\n",
    "        if len(id_) >= min_count:\n",
    "            indices.extend(id_[:min_count])\n",
    "        else:\n",
    "            print(f\"Warning: Not enough samples for label '{label}'. Found {len(id_)} samples.\")\n",
    "    return features_[indices], labels_[indices], True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952cb33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SVMClassification class\n",
    "svm_classifier = SVMClassification(train_data_labels)\n",
    "\n",
    "# Load the data\n",
    "# components = ['x', 'z']\n",
    "# components = ['x', 'z', 'calf', 'tigh', 'hip']\n",
    "components = [\n",
    "         ['z'],\n",
    "        #  ['x','z'],\n",
    "        #  ['x','z', 'tigh'],\n",
    "        #  ['x','z', 'hip'],\n",
    "        #  ['x','z', 'calf', 'tigh'],\n",
    "        #  ['x','z', 'calf', 'tigh', 'hip']\n",
    "        ]\n",
    "\n",
    "cmp = {\n",
    "    'fl-contact': [f'fl-{comp}' for comp in components[0]],\n",
    "    'fr-contact': [f'fr-{comp}' for comp in components[0]],\n",
    "    'rl-contact': [f'rl-{comp}' for comp in components[0]],\n",
    "    'rr-contact': [f'rr-{comp}' for comp in components[0]],\n",
    "}\n",
    "comb_legs = False #currently combine legs logic will not work\n",
    "norm_data = True\n",
    "use_org_sig = True\n",
    "aug_param = {'wavelet': None,}\n",
    "# aug_param = {'wavelet': None, 'derivative':None,}\n",
    "# aug_param = {'wavelet': None, 'derivative':None, 'fft':None}\n",
    "# aug_param = {'correlation': None, 'derivative':None,}\n",
    "# aug_param = {'wavelet': None,}\n",
    "# aug_param = {}\n",
    "svm_classifier.create_feature_matrix_and_label(normalize_data=norm_data,\n",
    "                            components=cmp,\n",
    "                            combine_legs = comb_legs,\n",
    "                            data_padding_size=80,\n",
    "                            augmetation_params=aug_param,\n",
    "                            use_original_signal=use_org_sig,\n",
    "                            )\n",
    "unfiltered_train_fm = svm_classifier.feature_matrix.copy()\n",
    "unfiltered_train_labels = svm_classifier.labels.copy()\n",
    "svm_classifier.feature_matrix, svm_classifier.labels, success_ = adjust_same_length(svm_classifier.feature_matrix, svm_classifier.labels)\n",
    "\n",
    "if not success_:\n",
    "    raise AttributeError(\"Feature matrix not computed\")\n",
    "\n",
    "unique_labels, label_counts = np.unique(svm_classifier.labels, return_counts=True)\n",
    "for label, count in zip(unique_labels, label_counts):\n",
    "    print(f\"Label {label}: {count} samples\")\n",
    "\n",
    "print(f\"ratio {max(label_counts)/min(label_counts)}\")\n",
    "print(f\"feature matrix shape: {svm_classifier.feature_matrix.shape}\")\n",
    "print(f\"labels shape: {svm_classifier.labels.shape}\")\n",
    "print(f\"original data shape: {np.array(svm_classifier.original_data).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with sklearn \n",
    "#using python 3.8\n",
    "report_dir = os.path.join(parent_dir, \"svm_classification\")\n",
    "C = [1e3, 1e2, 1e1, 1]\n",
    "gamma = [ 1e-4, 1e-2, 1e-3,]\n",
    "# C = [1, 1e1, 1e2]\n",
    "# gamma = [0.1, 1, 10]\n",
    "C = [1000]\n",
    "gamma = [0.0001]\n",
    "svm_classifier.train_classifier(C=C, gamma=gamma, find_best_parameters=True, \n",
    "                                save_model=False, model_file_name=\"3class_model\", \n",
    "                                save_report=False, file_path=None)\n",
    "\n",
    "print(\"Training completed.\")\n",
    "print(\"Report: \\n\")\n",
    "# print(svm_classifier.report)\n",
    "svm_classifier.print_classification_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation_classifier = SVMClassification(validation_data_labels)\n",
    "validation_classifier.create_feature_matrix_and_label(normalize_data=norm_data,\n",
    "                            components=cmp,\n",
    "                            combine_legs = comb_legs,\n",
    "                            data_padding_size=80,\n",
    "                            augmetation_params=aug_param,\n",
    "                            use_original_signal=use_org_sig,\n",
    "                            )\n",
    "org_validation_fm = svm_classifier.scaler.transform(validation_classifier.feature_matrix.copy())\n",
    "org_validation_labels = validation_classifier.labels.copy()\n",
    "validation_classifier.feature_matrix, validation_classifier.labels, success_ = adjust_same_length(validation_classifier.feature_matrix, validation_classifier.labels)\n",
    "\n",
    "if not success_:\n",
    "    raise AttributeError(\"Feature matrix not computed\")\n",
    "\n",
    "print(f\"validation feature matrix shape: {validation_classifier.feature_matrix.shape}\")\n",
    "# unique_labels, label_counts = np.unique(validation_classifier.labels, return_counts=True)\n",
    "# for label, count in zip(unique_labels, label_counts):\n",
    "#     print(f\"Label {label}: {count} samples\")\n",
    "\n",
    "# print(f\"ratio {max(label_counts)/min(label_counts)}\")\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# features_ = scaler.fit_transform(validation_classifier.feature_matrix)\n",
    "features_ = svm_classifier.scaler.transform(validation_classifier.feature_matrix)\n",
    "# features_ = validation_classifier.feature_matrix\n",
    "true_labels_ = validation_classifier.labels\n",
    "predictions_ = svm_classifier.latest_model.predict(features_)\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels_, predictions_))\n",
    "cm = ConfusionMatrixDisplay.from_predictions(true_labels_, predictions_, display_labels=svm_classifier.latest_model.classes_, cmap='Blues')\n",
    "\n",
    "# from sklearn.metrics import fbeta_score\n",
    "# f05 = fbeta_score(true_labels_, predictions_, beta=0.5, average=None)\n",
    "# print(f\"F-beta score (beta=0.5): {f05}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef06a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing MLP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def convert_labels(labels):\n",
    "    # Convert string labels to integers\n",
    "    label_map = {}\n",
    "    label_map['sand'] = 0\n",
    "    label_map['gravel'] = 1\n",
    "    label_map['wood'] = 2\n",
    "    label_map['clay'] = 3\n",
    "    # label_map['concrete'] = 4\n",
    "    return np.array([label_map[label] for label in labels], dtype=int)\n",
    "\n",
    "# Define MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): Number of input features.\n",
    "            hidden_layers (list): List of integers specifying the number of neurons in each hidden layer.\n",
    "            output_size (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "\n",
    "        # Add hidden layers dynamically\n",
    "        for i, hidden_size in enumerate(hidden_layers):\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            # layers.append(nn.BatchNorm1d(hidden_size))  # Add batch normalization\n",
    "            layers.append(nn.ReLU())  # You can replace ReLU with other activation functions\n",
    "            layers.append(nn.Dropout(0.1))  # Optional dropout\n",
    "            prev_size = hidden_size\n",
    "\n",
    "        # Add the output layer\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "\n",
    "        # Create the sequential model\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return F_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return F_loss.sum()\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "def train_MLP(train_features, train_labels, validation_features, validation_labels, print_confusion_matrix=False):\n",
    "    # Example usage\n",
    "    X = train_features\n",
    "    # print(f\"X shape: {X.shape}\")\n",
    "    y = convert_labels(train_labels)\n",
    "\n",
    "    op_class, label_counts = np.unique(y, return_counts=True)\n",
    "    # ul, lc = np.unique(y, return_counts=True)\n",
    "    # for label, count in zip(ul, lc):\n",
    "    #     print(f\"Label {label}: {count} samples\")\n",
    "\n",
    "    # Preprocess\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_validation = scaler.transform(validation_features)\n",
    "    # Convert to tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    X_validation_tensor = torch.tensor(X_validation, dtype=torch.float32)\n",
    "    y_validation_tensor = torch.tensor(convert_labels(validation_labels), dtype=torch.long)\n",
    "\n",
    "    input_size = X.shape[1]\n",
    "    hidden_layers = [256, 128, 64]  # Three hidden layers\n",
    "    # hidden_layers = [512, 256, 128, 64, 16]  # Three hidden layers\n",
    "    output_size = len(op_class)\n",
    "\n",
    "    model = MLP(input_size, hidden_layers, output_size)\n",
    "    # Training setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # criterion = FocalLoss(alpha=1, gamma=2.0)\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "    epochs = int(1000*1.5)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # if epoch % 500 == 0:\n",
    "        #     print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_preds = model(X_test_tensor).argmax(dim=1)\n",
    "        valid_preds = model(X_validation_tensor).argmax(dim=1)\n",
    "        \n",
    "        test_score = accuracy_score(y_test_tensor, test_preds)\n",
    "        validation_score = accuracy_score(y_validation_tensor, valid_preds)\n",
    "        print(f\"Test score: {test_score:.2f} Validation score: {validation_score:.2f}\")\n",
    "        \n",
    "        if print_confusion_matrix and validation_score >= 0.5:\n",
    "            # ConfusionMatrixDisplay.from_predictions(y_test_tensor, test_preds, display_labels=op_class, cmap='Blues')\n",
    "            print(classification_report(y_validation_tensor, valid_preds))\n",
    "            ConfusionMatrixDisplay.from_predictions(y_validation_tensor, valid_preds, display_labels=['sand', 'gravel', 'wood', 'clay'], cmap='Blues')\n",
    "    return validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9023dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class TerrainDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "    \n",
    "# filepath: /Users/brolin/Documents/RWTH/terrain_property_prediction/src/training_workbook.ipynb\n",
    "def train_MLP_with_batches(train_features, train_labels, validation_features, validation_labels, \n",
    "                          batch_size=32, print_confusion_matrix=False):\n",
    "    # Convert labels\n",
    "    X = train_features\n",
    "    y = convert_labels(train_labels)\n",
    "    \n",
    "    op_class, label_counts = np.unique(y, return_counts=True)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_validation = scaler.transform(validation_features)\n",
    "    \n",
    "    # Convert validation labels\n",
    "    y_validation = convert_labels(validation_labels)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TerrainDataset(X_train, y_train)\n",
    "    test_dataset = TerrainDataset(X_test, y_test)\n",
    "    validation_dataset = TerrainDataset(X_validation, y_validation)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Model setup\n",
    "    input_size = X.shape[1]\n",
    "    hidden_layers = [256, 128, 64]\n",
    "    output_size = len(op_class)\n",
    "    \n",
    "    model = MLP(input_size, hidden_layers, output_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "    \n",
    "    epochs = 1500  # Reduced epochs for batch learning\n",
    "    \n",
    "    # Training loop with batches\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for batch_features, batch_labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += batch_labels.size(0)\n",
    "            correct_predictions += (predicted == batch_labels).sum().item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct_predictions / total_samples\n",
    "        \n",
    "        # Validation every 50 epochs\n",
    "        if epoch % 50 == 0:\n",
    "            val_loss, val_acc = evaluate_model(model, validation_loader, criterion)\n",
    "            # print(f\"Epoch {epoch}: Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, \"\n",
    "            #       f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    test_loss, test_acc = evaluate_model(model, test_loader, criterion)\n",
    "    val_loss, val_acc = evaluate_model(model, validation_loader, criterion)\n",
    "    \n",
    "    print(f\"Final - Test Acc: {test_acc:.2f}, Validation Acc: {val_acc:.2f}\")\n",
    "    \n",
    "    if print_confusion_matrix:\n",
    "        # Generate confusion matrices\n",
    "        test_preds, test_true = get_predictions(model, test_loader)\n",
    "        val_preds, val_true = get_predictions(model, validation_loader)\n",
    "        \n",
    "        ConfusionMatrixDisplay.from_predictions(test_true, test_preds, display_labels=op_class, cmap='Blues')\n",
    "        ConfusionMatrixDisplay.from_predictions(val_true, val_preds, display_labels=op_class, cmap='Blues')\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion):\n",
    "    \"\"\"Evaluate model on given data loader\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_labels in data_loader:\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += batch_labels.size(0)\n",
    "            correct_predictions += (predicted == batch_labels).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def get_predictions(model, data_loader):\n",
    "    \"\"\"Get all predictions and true labels from data loader\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_labels in data_loader:\n",
    "            outputs = model(batch_features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_true.extend(batch_labels.cpu().numpy())\n",
    "    \n",
    "    return all_preds, all_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ee347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing MLP with different components and augmentations\n",
    "#if you want only one component, you can set the components variable to a single component\n",
    "norm_data = [True]\n",
    "comp_ = [\n",
    "        #  ['z'],\n",
    "        #  ['x','z'],\n",
    "        #  ['x','z', 'tigh'],\n",
    "        #  ['x','z', 'hip'],\n",
    "        #  ['x','z', 'calf', 'tigh'],\n",
    "         ['x','z', 'calf', 'tigh', 'hip']\n",
    "        ]\n",
    "\n",
    "augumentations = [\n",
    "                # {'wavelet': None,},\n",
    "                #  {'wavelet': None, 'derivative':None,},\n",
    "                 {'wavelet': None, 'derivative':None, 'fft': None},\n",
    "                #  {'correlation': None,},\n",
    "                #  {'wavelet':None, 'correlation': None, },\n",
    "                ]\n",
    "\n",
    "for aug_param in augumentations:\n",
    "    print(f\"-----\\nAugmentations: {aug_param}\\n-----\")\n",
    "    for cmp_ in comp_:\n",
    "        print(f\"Components: {cmp_}\")\n",
    "        for nd in norm_data:\n",
    "\n",
    "            test_comp = {\n",
    "                'fl-contact': [f'fl-{comp}' for comp in cmp_],\n",
    "                'fr-contact': [f'fr-{comp}' for comp in cmp_],\n",
    "                'rl-contact': [f'rl-{comp}' for comp in cmp_],\n",
    "                'rr-contact': [f'rr-{comp}' for comp in cmp_],\n",
    "            }\n",
    "            train_classifier = SVMClassification(train_data_labels)\n",
    "            train_classifier.create_feature_matrix_and_label(normalize_data=norm_data,\n",
    "                            components=test_comp,\n",
    "                            combine_legs = False,\n",
    "                            data_padding_size=80,\n",
    "                            augmetation_params=aug_param,\n",
    "                            use_original_signal=True,\n",
    "                            )\n",
    "\n",
    "            validation_classifier = SVMClassification(validation_data_labels)\n",
    "            validation_classifier.create_feature_matrix_and_label(normalize_data=norm_data,\n",
    "                            components=test_comp,\n",
    "                            combine_legs = False,\n",
    "                            data_padding_size=80,\n",
    "                            augmetation_params=aug_param,\n",
    "                            use_original_signal=True,\n",
    "                            )\n",
    "            val_score = 0.0\n",
    "            counter=0\n",
    "            while (val_score < 0.5):\n",
    "                val_score = train_MLP(train_classifier.feature_matrix, train_classifier.labels,\n",
    "                                      validation_classifier.feature_matrix, validation_classifier.labels, print_confusion_matrix=True)\n",
    "                counter += 1\n",
    "                # train_MLP_with_batches(train_classifier.feature_matrix, train_classifier.labels,\n",
    "                #                       validation_classifier.feature_matrix, validation_classifier.labels, print_confusion_matrix=True)\n",
    "\n",
    "            print(f\"Number of attempts to reach validation score of 0.5: {counter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aab18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate multiple parameter combination for SVM Classifier \n",
    "\n",
    "norm_data = [True]\n",
    "comp_ = [\n",
    "         ['z'],\n",
    "         ['x','z'],\n",
    "         ['x','z', 'tigh'],\n",
    "         ['x','z', 'hip'],\n",
    "         ['x','z', 'calf', 'tigh'],\n",
    "         ['x','z', 'calf', 'tigh', 'hip']\n",
    "        ]\n",
    "# comp_ = [['z'],\n",
    "#         #  ['z', 'tigh'],\n",
    "#         #  ['x','z', 'hip'],\n",
    "#          ['z', 'calf'],\n",
    "#          ['z', 'hip'],\n",
    "#          ['x','z', 'hip']\n",
    "#         ]\n",
    "\n",
    "# aug_param = {'wavelet': None,}\n",
    "augumentations = [\n",
    "                {'wavelet': None,},\n",
    "                 {'wavelet': None, 'derivative':None,},\n",
    "                 {'wavelet': None, 'derivative':None, },\n",
    "                 {'wavelet': None, 'derivative':None, 'fft': None},\n",
    "                #  {'correlation': None,},\n",
    "                #  {'wavelet':None, 'correlation': None, },\n",
    "                ]\n",
    "# params = [0.1, 25,]\n",
    "# augment = False\n",
    "\n",
    "for aug_param in augumentations:\n",
    "    print(f\"\\nAugmentations: {aug_param}\\n-----\")\n",
    "    for cmp_ in comp_:\n",
    "        for nd in norm_data:\n",
    "\n",
    "            test_comp = {\n",
    "                'fl-contact': [f'fl-{comp}' for comp in cmp_],\n",
    "                'fr-contact': [f'fr-{comp}' for comp in cmp_],\n",
    "                'rl-contact': [f'rl-{comp}' for comp in cmp_],\n",
    "                'rr-contact': [f'rr-{comp}' for comp in cmp_],\n",
    "            }\n",
    "            svm_classifier = SVMClassification(train_data_labels)\n",
    "            svm_classifier.create_feature_matrix_and_label(normalize_data=norm_data,\n",
    "                            components=test_comp,\n",
    "                            combine_legs = False,\n",
    "                            data_padding_size=80,\n",
    "                            augmetation_params=aug_param,\n",
    "                            use_original_signal=True,\n",
    "                            )\n",
    "            \n",
    "            svm_classifier.feature_matrix, svm_classifier.labels, success_ = adjust_same_length(svm_classifier.feature_matrix, svm_classifier.labels)\n",
    "            \n",
    "            C = [1e3, 1e2, 1e1, 1]\n",
    "            gamma = [ 1e-4, 1e-2, 1e-3,]\n",
    "            \n",
    "            svm_classifier.train_classifier(C=C, gamma=gamma, find_best_parameters=True, \n",
    "                                            save_model=False, model_file_name=\"3class_model\", \n",
    "                                            save_report=False, file_path=None)\n",
    "            \n",
    "            validation_classifier = SVMClassification(validation_data_labels)\n",
    "            validation_classifier.create_feature_matrix_and_label(normalize_data=norm_data,\n",
    "                            components=test_comp,\n",
    "                            combine_legs = False,\n",
    "                            data_padding_size=80,\n",
    "                            augmetation_params=aug_param,\n",
    "                            use_original_signal=True,\n",
    "                            )\n",
    "            validation_classifier.feature_matrix, validation_classifier.labels, success_ = adjust_same_length(validation_classifier.feature_matrix, validation_classifier.labels)\n",
    "            features_ = svm_classifier.scaler.transform(validation_classifier.feature_matrix)            \n",
    "            true_labels_ = validation_classifier.labels\n",
    "            predictions_ = svm_classifier.latest_model.predict(features_)\n",
    "            validation_score_ = accuracy_score(true_labels_, predictions_)\n",
    "            # print(f\"norm_data: {nd} | comps: {cmp_} | train_score: {svm_classifier.classification_report['report']['accuracy']:.2f} \"\n",
    "            #       f\"val_score: {validation_score_:.2f} | feature_shape: {svm_classifier.feature_matrix.shape}\") \n",
    "            print(f\"comps: {cmp_} | train_score: {svm_classifier.classification_report['report']['accuracy']:.2f} \"\n",
    "                  f\"val_score: {validation_score_:.2f} \") \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a39a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from terrain_classification.svm_classification.predict_svm import SVMPredictor\n",
    "# from terrain_classification.svm_classification.train_svm import SVMClassification\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from joblib import load\n",
    "# # Create an instance of the PredictSVM class\n",
    "# parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"terrain_classification\"))\n",
    "# file_name = \"3class_model\"\n",
    "# # file_name = \"gravel_concrete_model\"\n",
    "# model_file = os.path.join(parent_dir, \"svm_classification/models\", f\"{file_name}.joblib\")\n",
    "# scaler_path = os.path.join(parent_dir, \"svm_classification/models\", f\"{file_name}-scaler.pkl\")\n",
    "# # scaler = load(scaler_path)\n",
    "# predictor = SVMPredictor(model_path=model_file)\n",
    "# two_class_model = load(os.path.join(parent_dir, \"svm_classification/models\", \"2class_model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd0da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot samples from each class\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# step_dict = np.array(test_classifier.original_data)\n",
    "# print(step_dict.shape)\n",
    "# # print(step_dict.keys())\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for i, label in enumerate(np.unique(test_classifier.labels)):\n",
    "#     # if label == 'sand':\n",
    "#     #     continue\n",
    "#     indices = np.where(test_classifier.labels == label)[0]\n",
    "#     print(f\"Label {label}: {len(indices)} samples\")\n",
    "#     if len(indices) > 0:\n",
    "#         # Select a random sample from the indices\n",
    "#         index = np.random.choice(indices)\n",
    "#         print(f\"index: {index}\")\n",
    "#         # Plot the sample\n",
    "#         # plt.plot(step_dict[index][:, 0], step_dict[index][:, 1], label=label)\n",
    "#         plt.plot(step_dict[index], label=label)\n",
    "# plt.title(\"Samples from each class\")\n",
    "# plt.xlabel(\"X-axis\")\n",
    "# plt.ylabel(\"Y-axis\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c7438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Best Parameters: {'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "# Best Parameters with combined legs: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
    "rf = RandomForestClassifier(n_estimators=20, max_depth=None, max_features='log2', \n",
    "                            min_samples_split=5, random_state=42)\n",
    "rf.fit(svm_classifier.feature_matrix, svm_classifier.labels)\n",
    "predictions_rf = rf.predict(validation_classifier.feature_matrix)\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 500],\n",
    "#     'max_depth': [10, 20, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'max_features': ['sqrt', 'log2']\n",
    "# }\n",
    "\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=10, scoring='f1_weighted', verbose=2, n_jobs=-1)\n",
    "# grid_search.fit(svm_classifier.feature_matrix, svm_classifier.labels)\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# predictions_rf = grid_search.predict(validation_classifier.feature_matrix)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(validation_classifier.labels, predictions_rf))\n",
    "# cm_rf = ConfusionMatrixDisplay.from_predictions(validation_classifier.labels, predictions_rf, display_labels=svm_classifier.latest_model.classes_, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8518e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing for MLP\n",
    "from terrain_classification.wavelet_analysis import WaveletAnalysis\n",
    "from terrain_classification.data_augmentation import DataAugmentation\n",
    "\n",
    "wa = WaveletAnalysis()\n",
    "da = DataAugmentation()\n",
    "\n",
    "org_data = np.array(svm_classifier.original_data)\n",
    "# org_labels = np.array(unfiltered_labels)\n",
    "print(f\"org shape: {org_data.shape}\")\n",
    "org_labels = unfiltered_train_labels\n",
    "# org_labels = org_labels.reshape(-1, 1)\n",
    "\n",
    "wave_results = np.array(wa.perform_analysis(org_data))\n",
    "# print(f'wave shape: {wave_results.shape}')\n",
    "fft_signals = []\n",
    "for signal in org_data:\n",
    "    fft_signal = svm_classifier.data_augmentation.low_pass_filter(signal)\n",
    "    fft_signals.append(fft_signal)\n",
    "\n",
    "noise_signals = []\n",
    "for signal in org_data:\n",
    "    noise_signal = svm_classifier.data_augmentation.add_noise(signal, 0.1)\n",
    "    noise_signals.append(noise_signal)\n",
    "\n",
    "# augmented_ = feature_augmentation(['wavelet'], org_data)\n",
    "# print(f\"lenght: {len(fft_signals[0])}\")\n",
    "final_feature_matrix = []\n",
    "final_labels = []\n",
    "\n",
    "# aug_types = ['fft', 'wavelets']\n",
    "# for data, label in zip (org_data, org_labels):\n",
    "\n",
    "# for data_, fft_sig, wav_res, label in zip(org_data, fft_signals, wave_results, org_labels):\n",
    "    # final_feature_matrix.append(np.hstack((data_.flatten(), fft_sig.flatten())))\n",
    "for feature, fft_sig, wav_res, noi,  label in zip(org_data, fft_signals, wave_results, noise_signals, org_labels):\n",
    "    final_feature_matrix.append(np.hstack((feature.flatten(), noi.flatten(), fft_sig.flatten(), wav_res.flatten())))\n",
    "    # final_feature_matrix.append(np.hstack((feature.flatten(), fft_sig.flatten())))\n",
    "    # for aug_typ in aug_types:\n",
    "    #     augmented_ = feature_augmentation(aug_typ, data)\n",
    "    final_labels.append(label)\n",
    "\n",
    "final_feature_matrix = np.array(final_feature_matrix)\n",
    "final_labels = np.array(final_labels)\n",
    "\n",
    "# final_feature_matrix, final_labels = adjust_same_length(final_feature_matrix, final_labels)\n",
    "print(f'feature size: {final_feature_matrix.shape}')\n",
    "print(f'label size: {final_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import fft\n",
    "# from terrain_classification.wavelet_analysis import WaveletAnalysis\n",
    "# from terrain_classification.data_augmentation import DataAugmentation\n",
    "\n",
    "# wa = WaveletAnalysis()\n",
    "# da = DataAugmentation()\n",
    "\n",
    "# def feature_augmentation (names, signals):\n",
    "#     augmented_sig = []\n",
    "#     for name in names:\n",
    "#         if name == 'fft':\n",
    "#             # for sig in signals:\n",
    "#             fft_sig = da.low_pass_filter(signals)\n",
    "#             augmented_sig.append(fft_sig.flatten())\n",
    "\n",
    "#         if name == 'wavelet':\n",
    "#             wave_result = wa.perform_analysis(signals)\n",
    "\n",
    "#             for res in wave_result:\n",
    "#                 augmented_sig.append(res.flatten())\n",
    "\n",
    "#     return augmented_sig\n",
    "\n",
    "# org_data = np.array(svm_classifier.original_data)\n",
    "# # org_labels = np.array(unfiltered_labels)\n",
    "# print(f\"org shape: {org_data.shape}\")\n",
    "# org_labels = unfiltered_train_labels\n",
    "# # org_labels = org_labels.reshape(-1, 1)\n",
    "\n",
    "# wave_results = np.array(wa.perform_analysis(org_data))\n",
    "# # print(f'wave shape: {wave_results.shape}')\n",
    "# fft_signals = []\n",
    "# for signal in org_data:\n",
    "#     fft_signal = svm_classifier.data_augmentation.low_pass_filter(signal)\n",
    "#     fft_signals.append(fft_signal)\n",
    "\n",
    "# # augmented_ = feature_augmentation(['wavelet'], org_data)\n",
    "# print(f\"lenght: {len(fft_signals[0])}\")\n",
    "# final_feature_matrix = []\n",
    "# final_labels = []\n",
    "\n",
    "# aug_types = ['wavelets']\n",
    "# for data, label in zip (org_data, org_labels):\n",
    "#     aug_ = feature_augmentation(aug_types, data)\n",
    "#     print(f'aug shape: {np.array(aug_).shape}')\n",
    "\n",
    "# # for data_, fft_sig, wav_res, label in zip(org_data, fft_signals, wave_results, org_labels):\n",
    "#     # final_feature_matrix.append(np.hstack((data_.flatten(), fft_sig.flatten())))\n",
    "# # for feature, fft_sig, wav_res, label in zip(org_data, fft_signals, wave_results, org_labels):\n",
    "# #     final_feature_matrix.append(np.hstack((feature.flatten(), fft_sig.flatten(), wav_res.flatten())))\n",
    "# #     # for aug_typ in aug_types:\n",
    "# #     #     augmented_ = feature_augmentation(aug_typ, data)\n",
    "# #     final_labels.append(label)\n",
    "\n",
    "# final_feature_matrix = np.array(final_feature_matrix)\n",
    "# final_labels = np.array(final_labels)\n",
    "# print(f'feature size: {final_feature_matrix.shape}')\n",
    "# print(f'label size: {final_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab39b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('rf', rf), ('svc', svm_classifier.latest_model)], voting='hard')\n",
    "voting_clf.fit(svm_classifier.feature_matrix, svm_classifier.labels)\n",
    "predictions_voting = voting_clf.predict(test_classifier.feature_matrix)\n",
    "print(\"Voting Classifier Classification Report:\")\n",
    "print(classification_report(test_classifier.labels, predictions_voting))\n",
    "ConfusionMatrixDisplay.from_predictions(test_classifier.labels, predictions_voting, display_labels=voting_clf.classes_, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51687039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two and three class ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "two_three_ensemble = VotingClassifier(estimators=[\n",
    "                    ('svc3', predictor.model), \n",
    "                    ('svc2', two_class_model)], voting='hard', \n",
    "                    weights=[10, 1], verbose=2)\n",
    "two_three_ensemble.fit(svm_classifier.feature_matrix, svm_classifier.labels)\n",
    "predictions_ensemble = two_three_ensemble.predict(test_classifier.feature_matrix)\n",
    "print(\"Ensemble Classifier Classification Report:\")\n",
    "print(classification_report(test_classifier.labels, predictions_ensemble))\n",
    "ConfusionMatrixDisplay.from_predictions(test_classifier.labels, predictions_ensemble, \n",
    "                                        cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7595691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom ensemble prediction\n",
    "def custom_ensemble_predict(X):\n",
    "    # Get probabilities from both models\n",
    "    prob_three_class = predictor.model.predict_proba(X)\n",
    "    # print(\"prob_three_class\", prob_three_class)\n",
    "    prob_two_class = two_class_model.predict_proba(X)\n",
    "    # print(\"prob_two_class\", prob_two_class)\n",
    "\n",
    "    # Combine predictions (example: prioritize three-class SVC)\n",
    "    final_predictions = []\n",
    "    for i, prob in enumerate(prob_two_class):\n",
    "        if max(prob) > 0.7:  # High confidence from three-class SVC\n",
    "            final_predictions.append(predictor.model.classes_[np.argmax(prob)])\n",
    "        else:  # Use two-class SVC for refinement\n",
    "            final_predictions.append(two_class_model.classes_[np.argmax(prob_three_class[i])])\n",
    "    return final_predictions\n",
    "\n",
    "custom_predictions = custom_ensemble_predict(features_)\n",
    "\n",
    "print(\"Custom Ensemble Classifier Classification Report:\")\n",
    "print(classification_report(true_labels_, custom_predictions))\n",
    "ConfusionMatrixDisplay.from_predictions(true_labels_, custom_predictions, \n",
    "                                         cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78475d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #to train with cuML, we need to convert the labels to integers\n",
    "# l_ = ['sand', 'gravel', 'concrete']\n",
    "# min_len = [len(np.where(svm_classifier.labels == l)[0]) for l in l_ if len(np.where(svm_classifier.labels == l)[0]) > 0]\n",
    "\n",
    "# print(f\"min_len {min_len}\")\n",
    "# new_ids = np.empty(0)\n",
    "\n",
    "# if use_sand:\n",
    "#     new_ids = np.concatenate((new_ids, np.where(svm_classifier.labels == 'sand')[0]))\n",
    "# if use_gravel:\n",
    "#     new_ids = np.concatenate((new_ids, np.where(svm_classifier.labels == 'gravel')[0]))\n",
    "# if use_concrete:\n",
    "#     new_ids = np.concatenate((new_ids, np.where(svm_classifier.labels == 'concrete')[0]))\n",
    "\n",
    "# new_ids = new_ids.astype(int)\n",
    "# new_labels = svm_classifier.labels[new_ids]\n",
    "# new_features = svm_classifier.feature_matrix[new_ids]\n",
    "\n",
    "# print(f\"new labels shape {new_labels.shape}\")\n",
    "# print(f\"new features shape {new_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7388fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(labels):\n",
    "    # Convert string labels to integers\n",
    "    label_map = {}\n",
    "    label_map['sand'] = 0\n",
    "    label_map['gravel'] = 1\n",
    "    label_map['concrete'] = 2\n",
    "    return np.array([label_map[label] for label in labels], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca60fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use miniconda python 3.12\n",
    "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(svm_classifier.feature_matrix, svm_classifier.labels, test_size=0.2, random_state=42)\n",
    "# new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(new_features, new_labels, test_size=0.2, random_state=42)\n",
    "# print(f\"X type {new_X_train.dtype}\")\n",
    "# print(f\"y type {new_y_train.dtype}\")\n",
    "orig_label_train = new_y_train\n",
    "orig_label_test = new_y_test\n",
    "new_y_train = convert_labels(new_y_train)\n",
    "new_y_test = convert_labels(new_y_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "new_X_train = scaler.fit_transform(new_X_train)\n",
    "new_X_test = scaler.transform(new_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2cf247",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from cuml.svm import SVC as cmSVC\n",
    "from cuml.metrics import accuracy_score\n",
    "\n",
    "# print(\"Creating SVC model\")\n",
    "# c = [0.1, 1, 10, 100]\n",
    "c = [1000, 10, 100]\n",
    "g = [0.001, 0.01, 0.1, 1]\n",
    "# g = ['scale', 'auto']\n",
    "# g = [0.01, 1]\n",
    "kernel = ['rbf']\n",
    "# kernel = ['rbf', 'poly', 'sigmoid']\n",
    "c\n",
    "# for c_, g_ in zip(c, g):\n",
    "for k_ in kernel:\n",
    "    for c_ in c:\n",
    "        for g_ in g:\n",
    "        # print(f\"Trying c: {c_} g: {g_}\")\n",
    "        # print(f\"accuracy {accuracy_score(new_y_pred, new_y_test)}\")\n",
    "            new_svc = cmSVC(kernel=k_, C=c_, gamma=g_, cache_size=2000)\n",
    "            new_svc.fit(new_X_train, new_y_train)\n",
    "            new_y_pred = new_svc.predict(new_X_test)\n",
    "            print(f\"Trying c: {c_} g: {g_} kernel: {k_} -> Accuracy score: {accuracy_score(new_y_pred, new_y_test):.4f}\") \n",
    "            # print(classification_report(new_y_test, new_y_pred))\n",
    "            # print(\"=========================\")\n",
    "        print(\"----------------------\")\n",
    "    print(\"----------------------\")\n",
    "\n",
    "print(\"All Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "from cuml.svm import SVC as cmSVC\n",
    "\n",
    "# from sklearn.externals import joblib\n",
    "\n",
    "new_svc = cmSVC(kernel='rbf', C=100, gamma=0.01, cache_size=2000)\n",
    "new_svc.fit(new_X_train, new_y_train)\n",
    "print(\"Training done\")\n",
    "# sk_model = new_svc.to_sklearn()\n",
    "# dump(sk_model, os.path.join(parent_dir, 'svm_classification/cpu_test_model.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e31f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "# import cuml\n",
    "from sklearn.metrics import classification_report\n",
    "loaded_model = load(os.path.join(parent_dir, 'svm_classification/models/trained_test_model.joblib'))\n",
    "print(f\"loaded model {loaded_model}\")\n",
    "\n",
    "predictions_ = loaded_model.predict(new_X_train)\n",
    "print(classification_report(orig_label_train, predictions_))\n",
    "# print(f\"Accuracy: {accuracy_score(new_y_test, predictions_):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
